{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula: Number of Parameters in a Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 100, 100, 16)      80        \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, \n",
    "                 strides=2, padding='valid', \n",
    "    activation='relu', input_shape=(200, 200, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that K = filters, and F = kernel_size. Likewise, D_in is the last value in the input_shape tuple.  \n",
    "\n",
    "Since there are F\\*F\\*D_in weights per filter, and the convolutional layer is composed of K filters, the total number of weights in the convolutional layer is K\\*F\\*F\\*D_in. Since there is one bias term per filter, the convolutional layer has K biases. Thus, the number of parameters in the convolutional layer is given by K\\*F\\*F\\*D_in + K.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*2*2*1+16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula: Output Shape of a Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of a convolutional layer depends on the supplied values of kernel_size, input_shape, padding, and stride. Let's define a few variables:   \n",
    "\n",
    "+ K - the number of filters in the convolutional layer\n",
    "+ F - the height and width of the convolutional filters\n",
    "+ S - the stride of the convolution\n",
    "+ H_in - the height of the previous layer\n",
    "+ W_in - the width of the previous layer    \n",
    "Notice that K = filters, F = kernel_size, and S = stride. Likewise, H_in and W_in are the first and second value of the input_shape tuple, respectively.  \n",
    "\n",
    "\n",
    "The **depth** of the convolutional layer will always equal the number of filters K.  \n",
    "\n",
    "\n",
    "If padding = 'same', then the spatial dimensions of the convolutional layer are the following:\n",
    "+ **height** = ceil(float(H_in) / float(S))\n",
    "+ **width** = ceil(float(W_in) / float(S))  \n",
    "\n",
    "If padding = 'valid', then the spatial dimensions of the convolutional layer are the following:\n",
    "+ **height** = ceil(float(H_in - F + 1) / float(S))\n",
    "+ **width** = ceil(float(W_in - F + 1) / float(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=3, strides=2, padding='same', \n",
    "    activation='relu', input_shape=(128, 128, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Pooling Layers in Keras\n",
    "You must include the following argument:\n",
    "\n",
    "+ pool_size - Number specifying the height and width of the pooling window.  \n",
    "\n",
    "\n",
    "There are some additional, optional arguments that you might like to tune:  \n",
    "\n",
    "+ strides - The vertical and horizontal stride. If you don't specify anything, strides will default to pool_size.\n",
    "+ padding - One of 'valid' or 'same'. If you don't specify anything, padding is set to 'valid'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling2d_9 (MaxPooling2 (None, 49, 49, 15)        0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "#MaxPooling2D(pool_size, strides, padding)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(MaxPooling2D(pool_size=3, strides=2,\\\n",
    "                       input_shape=(100, 100, 15),\n",
    "                       padding='valid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs For Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ cov layer:  \n",
    "increase depth  \n",
    "detect regional patterns in the image\n",
    "+ max pooling layer:   \n",
    "decrease width and heitht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ hyper-parameters need to be specified:  \n",
    "filters:16,32,64  \n",
    "kernel_size:2-5  \n",
    "strides:1   \n",
    "padding:\"same\"  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 16)        208       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 64)        8256      \n",
      "=================================================================\n",
      "Total params: 10,544\n",
      "Trainable params: 10,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#detect regional patterns i the image\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "#reduct dimensionality\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               512500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 528,054\n",
      "Trainable params: 528,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#detect regional patterns i the image\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "#reduct dimensionality\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())   #cnn feature extraction\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network begins with a sequence of three convolutional layers, followed by max pooling layers. These first six layers are designed to take the input array of image pixels and convert it to an array where all of the spatial information has been squeezed out, and only information encoding the content of the image remains. The array is then flattened to a vector in the seventh layer of the CNN. It is followed by two dense layers designed to further elucidate the content of the image. The final layer has one entry for each object class in the dataset, and has a softmax activation function, so that it returns probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to Remember  \n",
    "+ Always add a ReLU activation function to the Conv2D layers in your CNN. With the exception of the final layer in the network, Dense layers should also have a ReLU activation function.\n",
    "+ When constructing a network for classification, the final layer in the network should be a Dense layer with a softmax activation function. The number of nodes in the final layer should equal the total number of classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
